% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rss_cv.R
\name{rss.cv}
\alias{rss.cv}
\title{Cross-validation for robust subset selection}
\usage{
rss.cv(
  x,
  y,
  k = 0:min(nrow(x) - int, ncol(x), 20),
  h = function(n) round(seq(0.75, 1, 0.05) * n),
  int = TRUE,
  nfold = 10,
  ncv = 1,
  n.core = nfold * ncv,
  cv.objective = tmspe,
  ...
)
}
\arguments{
\item{x}{a matrix of predictors}

\item{y}{a vector of the response}

\item{k}{the number of predictors to minimise sum of squares over; by default a sequence from 0
to 20}

\item{h}{a function that takes the sample size that returns the number of observations to
minimise sum of squares over; by default produces a sequence from 75 to 100 percent of sample
size (in increments of 5 percent); a function is used here to facilitate varying sample sizes in
cross-validation}

\item{int}{a logical indicating whether to include an intercept}

\item{nfold}{the number of folds to use in cross-validation}

\item{ncv}{the number of times to repeat cross-validation; the results are averaged}

\item{n.core}{the number of cores to use in cross-validation; by default \code{nfold} *
\code{ncv} cores are used (if available)}

\item{cv.objective}{the cross-validation objective function; by default trimmed mean square
prediction error with 25 percent trimming}

\item{...}{any other arguments}
}
\value{
An object of class \code{rss.cv}; a list with the following components:
\item{mean.cv}{a matrix with the cross-validated values of \code{cv.objective}; each row
corresponds to a value of \code{k} and each column to a value of \code{h}}
\item{k.min}{the \code{k} yielding the lowest cross-validated \code{cv.objective}}
\item{h.min}{the \code{h} yielding the lowest cross-validated \code{cv.objective}}
\item{k}{the value of \code{k} that was passed in}
\item{h}{the value of \code{h} that was passed in}
}
\description{
Does (repeated) \code{K}-fold cross-validation for robust subset selection in
 parallel. In the interest of speed, uses heuristics without the mixed-integer solver.
}
\examples{
# Generate training data with mixture error
set.seed(1)
n <- 100
p <- 10
p0 <- 5
n.c <- 5
beta <- c(rep(1, p0), rep(0, p - p0))
x <- matrix(rnorm(n * p), n, p)
e <- rnorm(n, c(rep(10, n.c), rep(0, n - n.c)))
y <- x \%*\% beta + e

# Cross-validate robust subset selection models
cv <- rss.cv(x, y, k = 0:10, h = function(n) round(c(0.95, 1.00) * n), n.core = 1)

# Plot cross-validation results
plot(cv)
}
\references{
Thompson, R. (2021). 'Robust subset selection'. arXiv:
\href{https://arxiv.org/abs/2005.08217}{2005.08217}.
}
\author{
Ryan Thompson <ryan.thompson@monash.edu>
}
