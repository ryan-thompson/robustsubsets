% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cv-rss.R
\name{cv.rss}
\alias{cv.rss}
\title{Cross-validated robust subset selection}
\usage{
cv.rss(
  x,
  y,
  k = 0:min(nrow(x) - 1, ncol(x), 20),
  h = function(n) round(seq(0.75, 1, 0.05) * n),
  mio = "min",
  nfold = 10,
  cv.loss = tmspe,
  cluster = NULL,
  ...
)
}
\arguments{
\item{x}{a predictor matrix}

\item{y}{a response vector}

\item{k}{the number of predictors to minimise sum of squares over; by default a sequence from 0
to 20}

\item{h}{a function that takes the sample size that returns the number of observations to
minimise sum of squares over; by default produces a sequence from 75 to 100 percent of sample
size (in increments of 5 percent); a function is used here to facilitate varying sample sizes in
cross-validation}

\item{mio}{one of 'min', 'all', or 'none' indicating whether to run the mixed-integer solver on
the \code{k} and \code{h} that minimise the cv error, all \code{k} and \code{h}, or none at all}

\item{nfold}{the number of folds to use in cross-validation}

\item{cv.loss}{an optional cross-validation loss-function to use; should accept a vector of
errors; by default trimmed mean square prediction error with 25\% trimming}

\item{cluster}{an optional cluster for running cross-validation in parallel; must be set up using
\code{parallel::makeCluster}}

\item{...}{any other arguments}
}
\value{
An object of class \code{cv.rss}; a list with the following components:
\item{cv}{a matrix with the cross-validated values of \code{cv.loss}; rows correspond to \code{k}
and columns to \code{h}}
\item{k}{a vector containing the values of \code{k} used in the fit}
\item{h}{a vector containing the values of \code{h} used in the fit}
\item{k.min}{the \code{k} yielding the lowest cross-validated \code{cv.loss}}
\item{h.min}{the \code{h} yielding the lowest cross-validated \code{cv.loss}}
\item{fit}{the fit from running \code{rss()} on the full data}
}
\description{
Fits a sequence of regression models using robust subset selection and then
cross-validates these models.
}
\examples{
# Generate training data with mixture error
set.seed(123)
n <- 100
p <- 10
p0 <- 5
ncontam <- 5
beta <- c(rep(1, p0), rep(0, p - p0))
x <- matrix(rnorm(n * p), n, p)
e <- rnorm(n, c(rep(10, ncontam), rep(0, n - ncontam)))
y <- x \%*\% beta + e

# Robust subset selection with cross-validation
fit <- cv.rss(x, y)

# Extract model coefficients, generate predictions, and plot cross-validation results
coef(fit)
predict(fit, x)
plot(fit)
}
\author{
Ryan Thompson <ryan.thompson@monash.edu>
}
